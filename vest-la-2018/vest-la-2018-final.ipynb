{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp \n",
    "import numpy as np \n",
    "from pandas import read_csv\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VEST documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Louisiana\n",
    "---------\n",
    "Election results from LA Secretary of State (https://voterportal.sos.la.gov/static/)\n",
    "Precinct shapefile from LA House of Representatives (http://house.louisiana.gov/H_Redistricting2011/default_LouisianaPrecinctShapefiles)\n",
    "\n",
    "Early votes were reported at the parish level. These were distributed by candidate to precincts based on their share of the precinct-level reported vote.\n",
    "\n",
    "Election results from the following parishes include \"alpha\" precincts in which voters within the same geographic boundaries are assigned to separate precincts by the first letter of their surname: Ascension, Assumption, Bossier, Caddo, East Baton Rouge, Lafayette, Lafourche, Rapides, St. Charles, St. Landry, Terrebonne\n",
    "\n",
    "The following precincts were modified to reflect alterations enacted prior to the 2018 election:\n",
    "\n",
    "Avoyelles: Merge 2-5B/6-1A  \n",
    "Plaquemines: Merge 2-1/2-2, 4-1/4-2, 5-1/5-2  \n",
    "St. Charles: Merge 2-6/2-7, 3-1/3-6, 3-3/3-4, 6-2/6-3, 6-4/6-5  \n",
    "Vermilion: Split 49B-1/49B-2  \n",
    "West Baton Rouge: Split 2-A/2-B; 11-A/11-B  \n",
    "  \n",
    "G18SOSRARD - Kyle Ardoin (Republican Party)  \n",
    "G18SOSREDM - \"Rick\" Edmongs (Republican Party)  \n",
    "G18SOSRSTO - Julie Stokes (Republican Party)  \n",
    "G18SOSRKEN - Thomas J. Kennedy III (Republican Party)  \n",
    "G18SOSRCRO - A.G. Crowe (Republican Party)  \n",
    "G18SOSRCLO - Heather Cloud (Republican Party)  \n",
    "G18SOSDCOL - \"Gwen\" Collins-Greenup (Democratic Party)  \n",
    "G18SOSDFRE - Renee Fontenot Free (Democratic Party)  \n",
    "G18SOSNMOR - Matthew Paul \"Matt\" Moreau (No Party)  \n",
    "  \n",
    "R18SOSRARD - Kyle Ardoin (Republican Party)  \n",
    "R18SOSDCOL - \"Gwen\" Collins-Greenup (Democratic Party)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links for data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Election data: https://voterportal.sos.la.gov/graphical\n",
    "\n",
    "Precinct shapefile from LA House of Representatives: https://house.louisiana.gov/H_redistricting2011/Shapefiles/2018%20LA%20Precincts%20for%20the%20Web.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Secretary of State General Election Run-off \n",
    "SoSG = pd.read_csv('./raw-data/election_results_la/SoSGeneral2018_LAPrecincts.csv')\n",
    "\n",
    "#Secretary of State Jungle Primary\n",
    "SoSP = pd.read_csv('./raw-data/election_results_la/SoSPrimary2018_LAPrecincts.csv')\n",
    "\n",
    "#Load precinct shapefile\n",
    "precincts = gp.read_file('./raw-data/2018 LA Precincts for the Web/2018 LA Precincts for the Web.shp')\n",
    "\n",
    "#Load final VEST file\n",
    "final = gp.read_file('./final_vest_la_2018/la_2018.shp')\n",
    "\n",
    "#Set options for pandas displays\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final[final[\"COUNTYFP10\"]==\"079\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify election data (alpha parishes and early vote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View VEST's early vote processing documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early votes were reported at the parish level. These were distributed by candidate to precincts based on their share of the precinct-level reported vote.\n",
    "\n",
    "Election results from the following parishes include \"alpha\" precincts in which voters within the same geographic boundaries are assigned to separate precincts by the first letter of their surname: Ascension, Assumption, Bossier, Caddo, East Baton Rouge, Lafayette, Lafourche, Rapides, St. Charles, St. Landry, Terrebonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the election data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SoSG.columns)\n",
    "print(SoSP.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the final VEST  columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the election dataset fields to match those in the VEST file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a rename dictionary for SoSP file based on the corresponding fields in the VEST file\n",
    "SoSP_rename_dict = {'Kyle Ardoin (REP)':'G18SOSRARD','Heather Cloud (REP)':'G18SOSRCLO','\"Gwen\" Collins-Greenup (DEM)':'G18SOSDCOL',\n",
    "            'A.G. Crowe (REP)':'G18SOSRCRO','\"Rick\" Edmonds (REP)':'G18SOSREDM', 'Renee Fontenot Free (DEM)':'G18SOSDFRE',\n",
    "            'Thomas J. Kennedy III (REP)':'G18SOSRKEN', 'Matthew Paul \"Matt\" Moreau (NOPTY)':'G18SOSNMOR','Julie Stokes (REP)':'G18SOSRSTO'}\n",
    "\n",
    "#Rename the SoSP file\n",
    "SoSP.rename(columns = SoSP_rename_dict, inplace=True)\n",
    "\n",
    "#Rename the two election result fields in the SoSG file based on their name in the VEST file\n",
    "SoSG.rename(columns = {'Kyle Ardoin (REP)':'R18SOSRARD','\"Gwen\" Collins-Greenup (DEM)':'R18SOSDCOL'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the the column names of the election results and the final VEST file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SoSG columns: ', SoSG.columns)\n",
    "print('SoSP columns: ', SoSP.columns)\n",
    "print('VEST columns: ', final.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to retrieve the totals of all of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function returns a dictionary of election results column names and totals for a dataframe.\n",
    "Input: pandas dataframe\n",
    "Output: dictionary with column name as key and the total sum of the column as the value'''\n",
    "\n",
    "def get_column_totals(df):\n",
    "    column_totals = [] #list for column sums \n",
    "    column_name = [] #list for column names\n",
    "    for i in df.columns:\n",
    "        if '18' in i: #only election results in the df\n",
    "            df[i] = df[i].astype(float) #converts the column to float\n",
    "            column_name.append(i) #add the column name to list of column names\n",
    "            col_tot = df[i].sum() #gets the sume of the column\n",
    "            col_tot = round(col_tot,0) #rounds the column total to nearest whole number\n",
    "            column_totals.append(col_tot) #adds the column total to the list of column sums\n",
    "    tot_dict = dict(zip(column_name,column_totals)) #zips the two lists into a dictionary\n",
    "    return tot_dict #returns the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the total votes for each candidate in the raw data to the VEST file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoSP_tot = get_column_totals(SoSP)\n",
    "SoSG_tot = get_column_totals(SoSG)\n",
    "final_tot = get_column_totals(final)\n",
    "SoSP_tot.update(SoSG_tot) #appends the SoSG_tot to the SoSP_tot dict (as this is the order that they are in the VEST file)\n",
    "SoS_tot = SoSP_tot\n",
    "SoSP_tot = get_column_totals(SoSP) #reruns SoSP_tot for SosP\n",
    "print('SoSP dictionary: ', SoSP_tot)\n",
    "print('\\nSoSG dictionary: ', SoSG_tot)\n",
    "print('\\nSoS total dictionary: ', SoS_tot)\n",
    "print('\\nVEST dictionary: ', final_tot)\n",
    "matching = SoS_tot == final_tot #boolean result between raw data and final election results \n",
    "print('\\nDo the election totals between the raw data and the final VEST file match (T/F)? ', str(matching))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we know that the results are the same, we need to assign the early vote by parish to the individual precincts based on candidate performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of parishes with 'alpha' precincts from VEST documentation above\n",
    "alpha_co = ['Ascension', 'Assumption', 'Bossier', 'Caddo', 'East Baton Rouge', 'Lafayette', 'Lafourche', 'Rapides', 'St. Charles', 'St. Landry', 'Terrebonne']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function to combine the alpha parish data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function takes a pandas dataframe of election results and a list of \"alpha counties\" and combines alpha precincts into one.\n",
    "Input: election data in a pandas data frame\n",
    "Optional input: list of counties/parishes that have alpha precincts\n",
    "Output: Dataframe with precincts grouped by unique identifier (merges the split alphas back together)'''\n",
    "def combine_alpha(df,alpha_co=alpha_co):\n",
    "    df['Precinct'] = df['Precinct'].astype(str) #make sure the precinct field is a string\n",
    "    #remove the ' A' by splitting the precinct field on the space for those in the alpha_co list, otherwise return the precinct column as is\n",
    "    df['Precinct'] = df.apply(lambda x: x['Precinct'].split(' ')[0] if x['Parish'] in alpha_co else x['Precinct'],axis=1) \n",
    "    #join parish, ward, precinct to get a groupby field \n",
    "    df['groupby'] = df[['Parish','Ward','Precinct']].apply(lambda x: '/'.join(x),axis=1)\n",
    "    #sum the votes that have the same value for group by and put in one row (this should be all that we modified to drop the ' A')\n",
    "    df = df.groupby(by='groupby').sum()\n",
    "    #reset the index\n",
    "    df.reset_index(inplace=True)\n",
    "    #add back all of the columns we got rid of except office (e.g. Parish, Ward, Precinct)\n",
    "    df['Parish'] = df['groupby'].apply(lambda x: x.split('/')[0])\n",
    "    df['Ward'] = df['groupby'].apply(lambda x: x.split('/')[1])\n",
    "    df['Precinct'] = df['groupby'].apply(lambda x: x.split('/')[2])\n",
    "    #delete groupby field, we won't need it again\n",
    "    del df['groupby']\n",
    "    #return the df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the alpha removal function on the SoSG and SoSP files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sosg = combine_alpha(SoSG)\n",
    "sosp = combine_alpha(SoSP)\n",
    "sosg_tot = get_column_totals(sosg)\n",
    "print('sosg dictionary: ', sosg_tot)\n",
    "sosp_tot = get_column_totals(sosp)\n",
    "print('sosp dictionary: ', sosp_tot)\n",
    "sosp_tot.update(sosg_tot)\n",
    "sos_tot = sosp_tot\n",
    "sosp_tot = get_column_totals(sosp)\n",
    "print('sos total dictionary: ', sos_tot)\n",
    "print('VEST final dictionary: ',final_tot)\n",
    "matching = sos_tot == final_tot\n",
    "print('Do the election totals between the processed alpha counties election data and the final VEST file match (T/F)? ', str(matching))\n",
    "print('There are ', sosg.shape[0], ' precincts in the sosg file (alpha counties assigned).')\n",
    "print('There are ', sosp.shape[0], ' precincts in the sosp file (alpha counties assigned).')\n",
    "print('There are ', final.shape[0],' precincts in the final VEST file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sosg[sosg[\"Parish\"]==\"Rapides\"])\n",
    "print(sosp[sosp[\"Parish\"]==\"Rapides\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function retrieves a list of all parishes in a dataframe.\n",
    "Input: pandas dataframe\n",
    "Output: list of parishes'''\n",
    "def county_list(df):\n",
    "    #Get list of all unique parishes in the dataset.\n",
    "    parishes = df['Parish'].unique()\n",
    "    return parishes\n",
    "\n",
    "'''This function creates a dictionary of parish names (key) and the dataframe subsetted to precincts in that parish (value). \n",
    "Input: pandas dataframe of election results\n",
    "Output: Dictionary where keys are parish names and values are dataframes where the parish field value is the key.'''\n",
    "def subset_county(df):\n",
    "    parish_list = county_list(df)\n",
    "    parish_dict = {}\n",
    "    for parish in parish_list:\n",
    "        parish_df = df[df.Parish == parish]\n",
    "        mini_dict = {parish : parish_df}\n",
    "        parish_dict.update(mini_dict)\n",
    "    return parish_dict\n",
    "\n",
    "'''This function assigns the early vote to each precinct based on respective candidate performance within a parish.\n",
    "Input: pandas dataframe of election results.\n",
    "Output: pandas dataframe of election results with early vote assigned to precincts within a parish, and the \"Early Vote\" precincts are removed.'''\n",
    "def get_early_vote(df):\n",
    "    county_dict = subset_county(df) #returns dictionary of each parish and the subsetted df of that parish\n",
    "    not_a_vote_col = ['Office','Parish','Ward','Precinct','groupby'] #columns that are not election results\n",
    "    new_parish_dfs = []\n",
    "    for k,v in county_dict.items():\n",
    "        early_vote_row = v[v.Ward=='Early Voting'] #subsets Early Vote ward in the parish df\n",
    "        for i in v.columns:\n",
    "            if i not in not_a_vote_col:\n",
    "                v[i] = v[i].astype(int) #make sure the election results column is in integer\n",
    "                early_vote_value = early_vote_row.iloc[0][i] #get the value of the early vote for that parish\n",
    "                sum_inperson = (v[i].sum())-early_vote_value #sum all of the in-person votes in the parish\n",
    "                #for each row in the parish, divide the candidate performance by the total in person vote, and then multiply that factor by the early_vote_value and add that to the original vote \n",
    "                v[i] = v[i].apply(lambda x: ((x/sum_inperson)*(early_vote_value)) + x)\n",
    "        #identiy all in-person precincts\n",
    "        in_person_rows = v[v.Ward != 'Early Voting']\n",
    "        #reassign v(the parish df) to only the in-person precincts, now that the Early Vote as been assigned\n",
    "        v = in_person_rows\n",
    "        #Create a 'Code' field that we can later use for joining\n",
    "        v['Parish'] = v['Parish'].apply(lambda x: x + ',')\n",
    "        v['Code'] = v[['Parish','Ward','Precinct']].apply(lambda x: ' '.join(x), axis=1)\n",
    "        #remove all unnecessary fields\n",
    "        del v['Parish']\n",
    "        del v['Ward']\n",
    "        del v['Precinct']\n",
    "        #add the dataframe to the list of new dataframes (one dataframe per parish)\n",
    "        new_parish_dfs.append(v)\n",
    "    #once the loop is done, concatonate all of the new dataframes into one dataframe\n",
    "    df = pd.concat(new_parish_dfs)\n",
    "    #return the df with early votes assigned and the early vote precincts removed (should reduce the overall row count by 64, as there are 64 parishes LA)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the early vote functions on the sosg and sosp datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the early vote for each election dataset\n",
    "SoSG_assigned = get_early_vote(sosg)\n",
    "SoSP_assigned = get_early_vote(sosp)\n",
    "\n",
    "#Check the row count for original and processed files\n",
    "print('SoSG row count prior to assigning early vote: ', str(sosg.shape[0]))\n",
    "print('SoSG row count after assigning early vote: ', str(SoSG_assigned.shape[0]))\n",
    "print('SoSP row count prior to assigning early vote: ',str(sosp.shape[0]))\n",
    "print('SoSP row count after assigning early vote: ',str(SoSP_assigned.shape[0]))\n",
    "\n",
    "#Check that the correct number of rows were removed\n",
    "parishes_in_la = county_list(sosg)\n",
    "num_parishes = len(parishes_in_la)\n",
    "diff_cases = int(sosg.shape[0])-int(SoSG_assigned.shape[0])\n",
    "matching = diff_cases == num_parishes\n",
    "print('Does SoSG now have ', num_parishes, ' fewer parishes than the SoSG alpha modified file (T/F)? ', str(matching))\n",
    "parishes_in_la = county_list(sosp)\n",
    "num_parishes = len(parishes_in_la)\n",
    "diff_cases = int(sosp.shape[0])-int(SoSP_assigned.shape[0])\n",
    "matching = diff_cases == num_parishes\n",
    "print('Does SoSP now have ', num_parishes, ' fewer parishes than the SoSP alpha modified file (T/F)? ', str(matching))\n",
    "\n",
    "\n",
    "\n",
    "#Check that the vote totals are still the same between the new files and the original files\n",
    "SoSG_assigned_tot = get_column_totals(SoSG_assigned)\n",
    "matching = SoSG_tot == SoSG_assigned_tot\n",
    "print('Does SosG dataframe with the early vote assigned have the same vote totals for each column as the original dataset (T/F)?', str(matching))\n",
    "SoSP_assigned_tot = get_column_totals(SoSP_assigned)\n",
    "matching = SoSP_tot == SoSP_assigned_tot\n",
    "print('Does SosP dataframe with the early vote assigned have the same vote totals for each column as the original dataset (T/F)?', str(matching))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at all data and modify fields accordingly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precinct columns: ,', list(precincts.columns))\n",
    "print('\\n')\n",
    "print('SoSG columns: ', list(sosg.columns))\n",
    "print('\\n')\n",
    "print('SoSP columns: ', list(sosp.columns))\n",
    "print('\\n')\n",
    "print('VEST columns: ', list(final.columns))\n",
    "#Look here, should these print statements be changed (changed them from SoSG and SoSP)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process precinct columns to match VEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precincts = precincts[['STATEFP10','COUNTYFP10','VTDST10','NAME10','geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join election data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_data = pd.merge(SoSP_assigned, SoSG_assigned)\n",
    "\n",
    "#Add Parish field back\n",
    "election_data['Parish'] = election_data['Code'].apply(lambda x: x.split(',')[0])\n",
    "election_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(election_data[(election_data[\"Parish\"]==\"Lafourche\")])\n",
    "print(election_data[(election_data[\"Parish\"]==\"Rapides\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validate[validate['Final Join']==\"079C4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a 'Code' field or unique identifier for the precinct geodataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function to retrieve the parish name based on the parish fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function uses the Census API to retrieve all of the county names and FIPS for a given state.\n",
    "Input: State FIPS code as a string.\n",
    "Output: pandas data frame of county fips and names for the given state.'''\n",
    "def county_names(state_fips):\n",
    "    \"\"\"Inputs: state fips code\n",
    "    Process: Retrieves a list of counties in the given state from the Census API.  \n",
    "    Outputs: A list of county fips codes in the state. \"\"\"\n",
    "    #uses the fips input into the census api\n",
    "    resp = requests.get(\n",
    "        \"https://api.census.gov/data/2010/dec/sf1\"\n",
    "        \"?get=NAME&for=county:*&in=state:{}\".format(state_fips)  #uses the fips input to locate the state\n",
    "    )\n",
    "    #retrieves the data as a json \n",
    "    test = resp.json()\n",
    "    header, *rows = resp.json()\n",
    "    #county column is \"county\"\n",
    "    county_column_index = header.index(\"county\")\n",
    "    county_fips = (row[county_column_index] for row in rows) #sequence of counties \n",
    "    county_names_index = header.index(\"NAME\")\n",
    "    county_names = (row[county_names_index] for row in rows) #names of the counties\n",
    "    county_fips = np.array(list(county_fips)) #make the sets into numpy arrays\n",
    "    county_names = np.array(list(county_names))\n",
    "    df = pd.DataFrame({'COUNTYFP10': county_fips, 'COUNTYNAMES': county_names}) #make pd dataframe of arrays\n",
    "    df[['COUNTY_NAME','state']] = df.COUNTYNAMES.str.split(\",\",expand=True)\n",
    "    del df['state']\n",
    "    del df['COUNTYNAMES']\n",
    "    return df  #returns the fips codes of all counties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the function for Louisiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_counties=county_names('22')\n",
    "\n",
    "#Create a Parish field and delete the old one\n",
    "LA_counties['Parish'] = LA_counties.apply(lambda x: x['COUNTY_NAME'][:-7], axis = 1)\n",
    "del LA_counties['COUNTY_NAME']\n",
    "\n",
    "#View the retrieved dataset\n",
    "LA_counties.head()\n",
    "print(LA_counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the precinct shapefile and the retrieved dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precincts_m = pd.merge(precincts,LA_counties, on=['COUNTYFP10'])\n",
    "\n",
    "#View the new dataframe\n",
    "precincts_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to match the election results with the precinct file, we need to perform string manipulation on the shapefile to create a common unique identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precincts_m['Precinct1'] = precincts_m['VTDST10'].apply(lambda x: x.split('-')[1] if x.find('-')!=-1 else x )\n",
    "precincts_m['PrecinctNumber'] = precincts_m['Precinct1'].str.replace('([A-Z]+)', '')\n",
    "precincts_m['County'] = precincts_m['Parish']\n",
    "precincts_m['PrecinctLetter'] = precincts_m['Precinct1'].str.extract('([A-Z]+)')\n",
    "precincts_m['County'] = precincts_m['County'].apply(lambda x: x.replace('La Salle','Lasalle'))\n",
    "precincts_m['County'] = precincts_m['County'].apply(lambda x: x.replace('the','The'))\n",
    "precincts_m['PrecinctNumber'] = precincts_m['PrecinctNumber'].apply(lambda x: '{0:0>2}'.format(x))\n",
    "precincts_m['PrecinctNumber'] = precincts_m.apply(lambda x: x['PrecinctNumber'].replace('0','') if (x['County']=='Catahoula') or (x['County'] == 'Grant')  or (x['County']=='Plaquemines') or (x['County']=='St. Charles') or (x['County']=='St. Helena') or (x['County']=='Winn') else x['PrecinctNumber'], axis=1)# NEW\n",
    "precincts_m['PrecinctNumber'] = precincts_m.apply(lambda x: '{0:0>3}'.format(x['PrecinctNumber']) if (x['County']=='Caddo') or (x['County']=='East Baton Rouge') or (x['County'] == 'Jefferson')  or (x['County'] == 'Lafayette')  or (x['County']=='Tangipahoa') or (x['County']=='Terrebonne') else x['PrecinctNumber'], axis=1) # NEW[]\n",
    "precincts_m['PrecinctNumber'] = precincts_m['PrecinctNumber'].astype(str)                                                                   \n",
    "precincts_m['PrecinctLetter'] = precincts_m['PrecinctLetter'].astype(str)                                                                   \n",
    "precincts_m['PrecinctLetter'] = precincts_m['PrecinctLetter'].replace('nan', '')\n",
    "precincts_m['Precinct'] = precincts_m['PrecinctNumber'].str.cat(precincts_m['PrecinctLetter'],sep=\"\")\n",
    "precincts_m['Ward'] = precincts_m['VTDST10'].apply(lambda x: x.split('-')[0] if x.find('-')!=-1 else '00')\n",
    "precincts_m['Ward'] = precincts_m['Ward'].apply(lambda x: '{0:0>2}'.format(x))\n",
    "precincts_m['Add2Precinct'] = precincts_m['VTDST10'].apply(lambda x: x.rsplit('-',2) if x.find('-') else '0')\n",
    "precincts_m['Add2Precinct'] = precincts_m['Add2Precinct'].apply(lambda x: x[2] if len(x) == 3 else '')\n",
    "precincts_m['PRECINCTS'] = precincts_m[['Precinct', 'Add2Precinct']].apply(lambda x: '-'.join(x), axis=1)\n",
    "precincts_m['PRECINCTS'] = precincts_m ['PRECINCTS'].apply(lambda x: x.replace('-', '') if x[-1] == '-' else x)\n",
    "#precincts_m['Ward'] = precincts_m.apply(lambda x: x['Ward'].replace(x['Ward'][-1],x['PRECINCTS'][0]) if (x['County']=='Rapides') or (x['County']=='St. Tammany') or (x['County']=='Evangeline') and (x['PRECINCTS'].endswith('([A-Z]+)')) else x['Ward'], axis=1) #***\n",
    "#precincts_m['Ward'] = precincts_m.apply(lambda x: x['Ward'].replace(x['Ward'][0],'0') if (x['County']=='Evangeline') else x['Ward'], axis=1)\n",
    "precincts_m['Ward'] = precincts_m.apply(lambda x: x['Ward'].replace(x['Ward'],'00') if (x['County']=='Rapides') or (x['County']=='Lafayette') or (x['County']=='St. Tammany') else x['Ward'], axis=1)\n",
    "precincts_m['PRECINCTS'] = precincts_m.apply(lambda x: x['PRECINCTS'].replace(x['PRECINCTS'][-1],'%temp%').replace(x['PRECINCTS'][:2],x['PRECINCTS'][-1]).replace('%temp%',x['PRECINCTS'][:2]) if (x['County']=='Rapides') or (x['County']=='St. Tammany') and (x['PRECINCTS'].endswith('([A-Z]+)')) else x['PRECINCTS'], axis=1)\n",
    "precincts_m['PRECINCTS'] = precincts_m.apply(lambda x: x['PRECINCTS'].replace(x['PRECINCTS'][-1],'%temp%').replace(x['PRECINCTS'][-2],x['PRECINCTS'][-1]).replace('%temp%',x['PRECINCTS'][-2]) if (x['County']=='Rapides') or (x['County']=='St. Tammany') and (x['PRECINCTS'].startswith('([A-Z]+)')) else x['PRECINCTS'],axis=1)\n",
    "#precincts_m['PRECINCTS'] = precincts_m.apply(lambda x: x['PRECINCTS'].replace(x['PRECINCTS'][-2],x['Ward'][1]) if (x['County']=='Lafayette') else x['PRECINCTS'],axis=1)\n",
    "precincts_m['Ward'] = precincts_m.apply(lambda x: x['Ward'].replace(x['Ward'][1],'0') if (x['County']=='Lafayette') else x['Ward'],axis=1)\n",
    "precincts_m['CountyComma'] = precincts_m['County'].apply(lambda x: x + ',')\n",
    "precincts_m['Code'] = precincts_m[['CountyComma','Ward', 'PRECINCTS']].apply(lambda x: ' '.join(x), axis=1)\n",
    "precincts_m['Code'] = precincts_m.apply(lambda x: x['CountyComma'] + ' 00 ' + str(x['Code'].split(' ')[1].replace('0','')) + '-' + str(x['Code'].split(' ')[2].replace('0', '')) if (x['County']=='Concordia') or (x['County']=='Morehouse') or (x['County']=='Sabine') or (x['County']=='Vermilion') else x['Code'], axis=1)\n",
    "#precincts_m['Code'] = precincts_m.apply(lambda x: x['Code']+ ' A' if x['County']=='East Baton Rouge' else x['Code'], axis = 1 )##NEW***\n",
    "precincts_m['Code'] = precincts_m.apply(lambda x: x['Code'].replace('-','') if (x['County'] == 'Morehouse') or (x['County']=='Vermilion') else x['Code'], axis = 1)# NEW***\n",
    "#precincts_m['Code'] = precincts_m.apply(lambda x: x['Code'].replace(' A','') if (x['County']=='Ascension') else x['Code'],axis =1)##NEW***\n",
    "precincts_m['Final Join'] = precincts_m[['COUNTYFP10','VTDST10']].apply(lambda x: ''.join(x),axis=1)\n",
    "\n",
    "#Clean the data\n",
    "columns_to_drop = ['Ward','PRECINCTS','County','Precinct','Precinct1','PrecinctNumber','PrecinctLetter','Add2Precinct','PRECINCTS','CountyComma']\n",
    "precincts_m  = precincts_m.drop(columns = columns_to_drop)\n",
    "\n",
    "#Look at the output of the string matching\n",
    "precincts_m.head(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge precincts per VEST's documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function to dissolve the precincts and a function to remove the old precincts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The function takes two rows in a geodataframe and merges them into one geometry.\n",
    "Inputs: Parish name (string), precinct 1 name (string), precinct 2 name (string)\n",
    "Optional Inputs: rename (string), gdf (geopandas gdf), parish_col (string), vtd_col (where the precinct names are pulled from, string), and precinct_col (field that is manipulated, string)\n",
    "Output: geodataframe of the dissolved precincts\n",
    "'''\n",
    "def precincts_for_dissolve(parish, prec1,prec2, rename='', gdf=precincts_m,parish_col = 'Parish', vtd_col = 'VTDST10', precinct_col = 'NAME10'):\n",
    "    parish_gdf = gdf[(gdf[parish_col]==parish)] #subsets input df to just precincts in the input parish\n",
    "    dissolve_gdf = parish_gdf[(parish_gdf[vtd_col]==prec1) | (parish_gdf[vtd_col]==prec2)] #subsets the parish df to be just the two rows that need to be merged\n",
    "    vtd_list = dissolve_gdf[vtd_col] \n",
    "    if (prec1 == '6-2') or (prec1=='6-4'):\n",
    "        dissolve_gdf = dissolve_gdf.dissolve(by=parish_col,aggfunc = 'last') #assigns by the last row\n",
    "    else:\n",
    "        dissolve_gdf = dissolve_gdf.dissolve(by=parish_col,aggfunc = 'first') #assigns by the first row\n",
    "    if rename == 'rename':\n",
    "        new_name = prec1.split('-')[0] #renames prec1 the first part befor the hyphen\n",
    "        dissolve_gdf[vtd_col]=dissolve_gdf[vtd_col].replace(prec1, new_name)\n",
    "        dissolve_gdf[precinct_col] = dissolve_gdf[precinct_col].replace('Precinct ' + prec1, 'Precinct ' + new_name) #renames the precinct name col\n",
    "    return dissolve_gdf #returns a geodataframe with one row: the dissolved geometries of the two rows\n",
    "\n",
    "'''The function takes dictionary of parishes and precincts and drops those from the geodataframe.\n",
    "Input: dictionary of parishes and precincts\n",
    "Option Input: parish column, vtd column\n",
    "Output: geodataframe with dropped precincts'''\n",
    "def drop_cases(drop_data_dict, gdf = precincts_m, parish_col = 'Parish',vtd_col = 'VTDST10'):\n",
    "    proj = gdf.crs\n",
    "    print('gdf shape before any alteration: ', gdf.shape)\n",
    "    for k,v in drop_data_dict.items():\n",
    "        parish_gdf = gdf[(gdf[parish_col]==k)]\n",
    "        gdf = gdf.drop(parish_gdf.index)\n",
    "        gdf.reset_index(drop=True,inplace=True)\n",
    "        #print('gdf shape after dropping ', k, ' ', gdf.shape)\n",
    "        #for i in v:\n",
    "        #    parish_gdf = parish_gdf.drop(parish_gdf[(gdf[vtd_col] == i)].index)\n",
    "        not_added = parish_gdf[parish_gdf[vtd_col].isin(v)]\n",
    "        #print('removed precincts from the dataframe: ', list(not_added[vtd_col]))\n",
    "        parish_gdf = parish_gdf[~parish_gdf[vtd_col].isin(v)]\n",
    "        #print('precincts staying in the df form the parish: ', list(parish_gdf[vtd_col]))\n",
    "        gdf = gp.GeoDataFrame(pd.concat([gdf,parish_gdf],ignore_index=True), crs = proj)\n",
    "        #print('gdf shape after adding back ', k, ' and dropping merged precincts ', gdf.shape)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the dissolve function on the precincts per VESTs documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Add in the info on processing here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "avoyelles = precincts_for_dissolve('Avoyelles','2-5B','6-1A')\n",
    "plaquemines1 = precincts_for_dissolve('Plaquemines','2-1','2-2')\n",
    "plaquemines2 = precincts_for_dissolve('Plaquemines','4-1','4-2')\n",
    "plaquemines3 = precincts_for_dissolve('Plaquemines', '5-1','5-2')\n",
    "st_charles1 = precincts_for_dissolve('St. Charles','2-6','2-7')\n",
    "st_charles2 = precincts_for_dissolve('St. Charles','3-1','3-6')\n",
    "st_charles3 = precincts_for_dissolve('St. Charles','3-3','3-4')\n",
    "st_charles4 = precincts_for_dissolve('St. Charles','6-2','6-3')\n",
    "st_charles5 = precincts_for_dissolve('St. Charles','6-4','6-5')\n",
    "\n",
    "#Add all of the dissolved gdfs to a list\n",
    "prec2replace = [avoyelles,plaquemines1,plaquemines2,plaquemines3,st_charles1,st_charles2,st_charles3,st_charles4,st_charles5]\n",
    "#assign proj to the crs of the original file\n",
    "proj = precincts_m.crs\n",
    "#concatonate the geodataframes into one geodataframe\n",
    "prec2replace = gp.GeoDataFrame(pd.concat(prec2replace, ignore_index=True), crs = proj)\n",
    "print('There are ', prec2replace.shape[0],' precincts that are dissolved to be added back')\n",
    "\n",
    "#create data drop dict to remove the select precincts\n",
    "\n",
    "drop_data_dict = {'Avoyelles':['2-5B','6-1A'],\n",
    "                 'Plaquemines':['2-1','2-2','4-1','4-2','5-1','5-2'],\n",
    "                 'St. Charles':['2-6','2-7','3-1','3-6','3-3','3-4','6-2','6-3','6-4','6-5']}\n",
    "\n",
    "#drop the precincts\n",
    "precincts_modified = drop_cases(drop_data_dict)\n",
    "print('There are ', precincts_modified.shape[0], ' precincts after dropping the cases to be removed. After adding in the merged cases there should be ', precincts_modified.shape[0]+prec2replace.shape[0])\n",
    "#Add the precincts back\n",
    "precincts_mod = gp.GeoDataFrame(pd.concat([precincts_modified,prec2replace],ignore_index=True), crs=proj)\n",
    "print('There are ', precincts_mod.shape[0], ' after adding back the precincts.')\n",
    "matching = precincts_mod.shape[0]==precincts_modified.shape[0]+prec2replace.shape[0]\n",
    "print('Does the new file have the expected number of precincts (T/F)? ', str(matching))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the final shapefile so it and the precinct file are the same. \n",
    "We have to modify the 'split' precincts in the final file since we don't know what they were split on,\n",
    "we will merge them back together to match the original file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the the LA counties file with the final file to get the parish names in the dataset\n",
    "final_merged = pd.merge(final,LA_counties, on=['COUNTYFP10'])\n",
    "\n",
    "#run the dissolve function for the counties that were indicated as 'split' in the metadata\n",
    "final_vermilion_dis = precincts_for_dissolve('Vermilion','49B-1','49B-2')\n",
    "final_wbr_dis = precincts_for_dissolve('West Baton Rouge','2A','2B','rename')\n",
    "final_wbr_dis2 = precincts_for_dissolve('West Baton Rouge','11A','11B','rename')\n",
    "final_p2r = [final_vermilion_dis,final_wbr_dis,final_wbr_dis2]\n",
    "proj = final.crs\n",
    "final_p2r = gp.GeoDataFrame(pd.concat(final_p2r,ignore_index=True), crs=proj)\n",
    "\n",
    "#run the data drop function for the 'split' counties\n",
    "drop_data_final = {'Vermilion':['49B-1','49B-2'],\n",
    "                  'West Baton Rouge':['2A','2B','11A','11B']}\n",
    "final_modi = drop_cases(drop_data_final,final_merged)\n",
    "final_modified = gp.GeoDataFrame(pd.concat([final_modi,final_p2r],ignore_index=True),crs=proj)\n",
    "final_modified['Final Join'] = final_modified[['COUNTYFP10','VTDST10']].apply(lambda x: ''.join(x),axis=1)\n",
    "print('There are ', final_modified.shape[0], ' precincts after dropping the cases to be removed. After adding in the merged cases there should be ', final_modi.shape[0]+final_p2r.shape[0])\n",
    "\n",
    "#Add the precincts back\n",
    "final_mod = gp.GeoDataFrame(pd.concat([precincts_modified,prec2replace],ignore_index=True), crs=proj)\n",
    "print('There are ', final_modi.shape[0], ' after adding back the precincts.')\n",
    "matching = final_mod.shape[0]==(final_modi.shape[0]+final_p2r.shape[0])\n",
    "print('Does the new file have the expected number of precincts (T/F)? ', str(matching))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm that the named precincts are the same between the raw and final files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace final file that we know is different after looking at the data\n",
    "\n",
    "unique_final = []\n",
    "for i in final_mod['Final Join']:\n",
    "    unique_final.append(i)\n",
    "unique_prec = []\n",
    "for i in precincts_mod['Final Join']:\n",
    "    unique_prec.append(i)\n",
    "differing = []\n",
    "for i in unique_final:\n",
    "    if i not in unique_prec:\n",
    "        print(i, ' not in precinct file')\n",
    "        differing.append(i)\n",
    "for i in unique_prec:\n",
    "    if i not in unique_final:\n",
    "        print(i, ' not in final file')\n",
    "        differing.append(i)\n",
    "\n",
    "print('Numer of unique values in Final Join filed in the precincts file: ', str(precincts_mod['Final Join'].nunique()))\n",
    "\n",
    "print('There are ', len(differing), ' precincts that are different between the two files. They are ', differing)\n",
    "matching = final_mod.shape[0]==precincts_mod.shape[0]\n",
    "print('Are there the same number of cases in the modified VEST and precinct files (T/F)? ', str(matching))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that the geometries themselves are the same between the two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mod[\"geometry\"]=final_mod.buffer(0) #buffer by 0 to remove any non polygons\n",
    "precincts_mod[\"geometry\"]=precincts_mod.buffer(0)\n",
    "proj = final_mod.crs #project to same projection\n",
    "precincts_mod = precincts_mod.to_crs(proj)\n",
    "final_mod = final_mod.to_crs(proj)\n",
    "final_mod =final_mod.sort_values(by=['Final Join']) #sort values by the unique field\n",
    "precincts_mod = precincts_mod.sort_values(by=['Final Join'])\n",
    "precincts_mod.reset_index(drop=True,inplace=True) #drop the index\n",
    "final_mod.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#see the differencebetween the precinct and final file\n",
    "file = precincts_mod.difference(final_mod)\n",
    "\n",
    "#Difference as a percentage is very very close to 0\n",
    "print('Difference between the precinct and final file area as a percentage of the precinct file area is ',str(sum(file.area)/sum(precincts_mod.area)))\n",
    "\n",
    "#To 6 decimal places, the two files are equal \n",
    "t_f_geom = list(final_mod.geom_almost_equals(precincts_mod,decimal=6))\n",
    "unique_geom = []\n",
    "for i in t_f_geom:\n",
    "    if i not in unique_geom:\n",
    "        unique_geom.append(i)\n",
    "for i in unique_geom:\n",
    "    percent = str((t_f_geom.count(i)/len(t_f_geom))*100) \n",
    "    print(str(t_f_geom.count(i)) + ' precincts are ' + str(i) + ' which is ' + percent + ' percent of all precincts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the election data to the precinct shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset the election data with necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_data = election_data[['G18SOSRARD', 'G18SOSREDM', 'G18SOSRSTO', 'G18SOSRKEN', 'G18SOSRCRO', 'G18SOSRCLO',\n",
    "                  'G18SOSDCOL', 'G18SOSDFRE', 'G18SOSNMOR', 'R18SOSRARD', 'R18SOSDCOL', \n",
    "                   'Parish','Code']]\n",
    "\n",
    "election_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(election_data[election_data[\"Code\"]==\"Rapides, 00 C04\"])\n",
    "print(election_data[election_data[\"Code\"]==\"Rapides, 00 C40\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(precincts_joined[precincts_joined[\"Code\"]==\"Rapides, 00 C04\"])\n",
    "print(precincts_joined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the election data totals have already been validated to the final data (before and after early vote assignment) we can join the data to the modified precincts geodataframe on the Code field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#precincts_joined = pd.merge(precincts_modified,election_data,on='Code')\n",
    "precincts_joined = pd.merge(precincts_modified,election_data,on=['Code'],how=\"inner\")\n",
    "\n",
    "print('Number of precincts in the election dataset: ', str(election_data.shape[0]))\n",
    "print('Number of precincts in the modified precincts dataset: ', str(precincts_mod.shape[0]))\n",
    "precincts_joined = precincts_joined.sort_values(by=['Final Join']) #sort by Final Join field\n",
    "#Subset the joined field by the necessary column order\n",
    "precincts_joined = precincts_joined[['STATEFP10','COUNTYFP10','VTDST10','NAME10','G18SOSRARD','G18SOSREDM','G18SOSRSTO','G18SOSRKEN','G18SOSRCRO','G18SOSRCLO','G18SOSDCOL','G18SOSDFRE','G18SOSNMOR','R18SOSRARD','R18SOSDCOL','geometry','Final Join']]\n",
    "print('Number of precincts in the joined election and precincts geodataframe: ',str(precincts_joined.shape[0]))\n",
    "print('Precincts that were successfully joined with election results as a percentage of election result precincts: ', str((precincts_joined.shape[0]/election_data.shape[0])*100))\n",
    "print('Precincts that were successfully joined with election results as a percentage of the modified precinct geodataframe: ', str((precincts_joined.shape[0]/precincts_mod.shape[0])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the final VEST file with the precinct shapefile with election results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add final join column to VEST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['Final Join'] = final[['COUNTYFP10','VTDST10']].apply(lambda x: ''.join(x),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the precinct/election file and the VEST dataset by joining them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = pd.merge(precincts_joined,final, on='Final Join') #merge on the 'Final Join column'\n",
    "\n",
    "print('Number of precincts in the joined precincts dataset: ', str(precincts_joined.shape[0]))\n",
    "print('Number of precincts in the final VEST dataset: ', str(final.shape[0]))\n",
    "print('Number of precincts in the joined precinct and final VEST file : ',str(validate.shape[0]))\n",
    "print('Precincts with election results that were successfully joined with the final file as a percentage of the precinct election results geodataframe: ', str((validate.shape[0]/precincts_joined.shape[0])*100))\n",
    "print('Precincts with election results that were successfully joined with the final file as a percentage of the precincts in the final file: ', str((validate.shape[0]/final.shape[0])*100))\n",
    "validate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Precinct Votes in the Validated File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validater_row (df, column_List):\n",
    "    matching_rows = 0\n",
    "    different_rows = 0\n",
    "    diff_list=[]\n",
    "    diff_values = []\n",
    "    max_diff = 0\n",
    "    \n",
    "    for j in range(0,len(df.index)):\n",
    "        same = True\n",
    "        for i in column_List:\n",
    "            left_Data = i + \"_x\"\n",
    "            right_Data = i + \"_y\"\n",
    "            diff = abs(df.iloc[j][left_Data]-df.iloc[j][right_Data])\n",
    "            if(diff != 0):\n",
    "                diff_values.append(abs(diff))\n",
    "                same = False\n",
    "                if(np.isnan(diff)):\n",
    "                    print(\"NaN value at diff is: \", df.iloc[j]['Final Join'])\n",
    "                if (diff>max_diff):\n",
    "                    print(\"New max diff is: \", str(max_diff))\n",
    "                    max_diff = diff\n",
    "                    print(df.iloc[j]['Final Join'])\n",
    "        if(same != True):\n",
    "            different_rows +=1\n",
    "            diff_list.append(df.iloc[j]['Final Join'])\n",
    "        else:\n",
    "            matching_rows +=1\n",
    "    print(\"There are \", len(df.index),\" total rows\")\n",
    "    print(different_rows,\" of these rows have election result differences\")\n",
    "    print(matching_rows,\" of these rows are the same\")\n",
    "    print(\"\")\n",
    "    print(\"The max difference between any one shared column in a row is: \", max_diff)\n",
    "    print(\"The average difference is: \", str(sum(diff_values)/len(diff_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validate[validate[\"Final Join\"]==\"0673-2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_List = ['G18SOSRARD', 'G18SOSREDM', 'G18SOSRSTO', 'G18SOSRKEN', 'G18SOSRCRO', 'G18SOSRCLO', 'G18SOSDCOL', 'G18SOSDFRE', 'G18SOSNMOR', 'R18SOSRARD', 'R18SOSDCOL']\n",
    "validater_row(validate,column_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validate[validate['Final Join']==\"079C4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the shapefiles of the merged file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the column totals of the joined file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_tots = get_column_totals(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all values that have a key that includes _x and add to a new list\n",
    "values_x = [value for key, value in validate_tots.items() if '_x' in key]\n",
    "#Remove the _x in the keys of the dict and add to a new list\n",
    "keys_x = [key for key, value in validate_tots.items() if '_x' in key]\n",
    "\n",
    "#Replace all of the _x keys with '' to remove it\n",
    "new_keys_x = []\n",
    "for key in keys_x:\n",
    "    new_key = key.replace('_x','')\n",
    "    new_keys_x.append(new_key)\n",
    "    \n",
    "#add the new_keys_x list and the values_x to a new dictionary of all x data\n",
    "validate_x = dict(zip(new_keys_x,values_x))\n",
    "\n",
    "#Repeate the same process as the _x data for the _y data\n",
    "values_y = [value for key, value in validate_tots.items() if '_y' in key]\n",
    "keys_y = [key for key, value in validate_tots.items() if '_y' in key]\n",
    "new_keys_y = []\n",
    "for key in keys_y:\n",
    "    new_key = key.replace('_y','')\n",
    "    new_keys_y.append(new_key)\n",
    "validate_y = dict(zip(new_keys_y,values_y))\n",
    "\n",
    "#print the two new dictionaries\n",
    "print(validate_x)\n",
    "print(validate_y)\n",
    "matching = validate_x == validate_y\n",
    "\n",
    "print('\\nAre there the election totals of the succesfully joined final and precinct/election file the same (T/F)? ', str(matching))\n",
    "print(\"\\nThese differences are likely due to the unknown rounding method, which would produce inconsistencies in the totals if not looking at the *entire* total (which aren't since we didn't have a 100% successful join.)\")\n",
    "\n",
    "#Determine the difference between the _x and the _y vote totals as a percentage (absolute value)\n",
    "vote_per_list = []\n",
    "for k,v in validate_x.items():\n",
    "    for k2,v2 in validate_y.items():\n",
    "        if k==k2: #if the keys are the same\n",
    "            print('Difference in vote between precinct/elections file and final VEST file for ', k, ' is ', str(abs(v2-v)))\n",
    "            vote_per = abs(((v2-v)/v2)*100)\n",
    "            print('Precentage of vote that is missing: ', str(vote_per))\n",
    "            vote_per_list.append(vote_per)\n",
    "            \n",
    "\n",
    "print('\\nThe maximum percentage difference in vote after joining is: ', max(vote_per_list))\n",
    "print('\\nThe minimum percentage difference in vote after joining is: ', min(vote_per_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations for Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw data available?\tYes\n",
    "\n",
    "Processing steps available?\tYes\n",
    "\n",
    "Able to replicate joining election data and shapefiles?\tYes, but this is slightly less good one but given the rate, but I would say yes still. You can print out the difference from like an outer join to see the ones that are off and you can tell that the vast majority are due to string matching not being 100% perfect.\n",
    "\n",
    "Able to replicate by joining demographic data?\tN/A\n",
    "\n",
    "Able to replicate by joining boundary data?\tN/A\n",
    "\n",
    "Successfully ran validation? Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
